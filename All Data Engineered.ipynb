{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is dedicated to the same as ANTM\n",
    "But it works only with all of the features and also runs an OLS model (only OLS because I know lasso and ridge won't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data = pd.read_pickle('full_country_data.pkl')\n",
    "\n",
    "\n",
    "country_data['r_home_war'] = country_data['r_home_war'].astype(float)\n",
    "#drop data deficit\n",
    "country_data = country_data.drop(['malnutrition','pov_ind','divorce','homeless','Continent','BothSexes','MalesNumber',\n",
    "                                 'FemalesNumber','marriage','marr_div_ratio'],axis=1)\n",
    "\n",
    "X,y = country_data.drop('bc_BothSexes',axis=1), country_data['bc_BothSexes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=13,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train['gdp'] = np.log(X_train.gdp)\n",
    "X_train['total_sex_ratio'] = 1/(X_train.total_sex_ratio)\n",
    "X_train['guns'] = np.log(X_train.guns+1)\n",
    "X_train['doc_ratio'] = np.log(X_train.doc_ratio)\n",
    "X_train['pop_dens'] = np.log(X_train.pop_dens)\n",
    "X_train['elevation'] = np.log(X_train.elevation)\n",
    "X_train['immigrants'] = np.log(X_train.immigrants)\n",
    "X_train['literacy'] = (X_train.literacy)**1/2\n",
    "X_train['gdppp'] = np.log(X_train.gdppp)\n",
    "X_train['population'] = np.log(X_train.population)\n",
    "X_train['children'] = X_train.children**2\n",
    "X_train['below_pov_line'] = np.log(X_train.below_pov_line)\n",
    "X_train['wine'] = np.log(X_train.wine+1)\n",
    "X_train['oth_alc'] = np.log(X_train.oth_alc+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_OLS(feature_matrix,target_series) :\n",
    "    \"\"\"\n",
    "    does a k_fold validation on a potential model to determine the average adj_r2 of each validation\n",
    "    \n",
    "    args:\n",
    "        target_series = series of dependent variable\n",
    "        feature_matrix = pd.DataFrame of predictors\n",
    "    returns :\n",
    "        mean adjusted r2 (maybe with list of features, undecided) for that model; float\n",
    "        \n",
    "    IMPORTANT NOTE : with smaller data sets, you will get weird results (aka negative adj_R2); the value\n",
    "    does still increase as the model improves though, so it should not be a problem long term.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 8)\n",
    "    r2s = cross_val_score(LinearRegression(), feature_matrix, target_series, cv=kf, scoring='r2')\n",
    "    return np.mean(r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_corr_check(feature_matrix,target_series,max_corr) :\n",
    "        \"\"\"\n",
    "    looks for any remaining high correlations and so that they can be looked at logically \n",
    "    \n",
    "    args:\n",
    "        target_series = np.series of dependent variable\n",
    "        feature_matrix = pd.DataFrame of predictors\n",
    "        max_corr = maximum correlation allowed between any two features (float; 0<max_corr<1)\n",
    "    returns :\n",
    "        list of highly (maybe with list of features, undecided) for that model\n",
    "        \n",
    "    \"\"\"\n",
    "        start_adj_r2 = validate_OLS(feature_matrix,target_series)\n",
    "        high_corrs = []\n",
    "        for col1 in feature_matrix.columns :\n",
    "            for col2 in feature_matrix.columns :\n",
    "                if col1 != col2 :\n",
    "                    corr = np.corrcoef(feature_matrix[col1],feature_matrix[col2])[0][1]\n",
    "                    if (abs(corr) >= max_corr and (col2, col1, corr) not in high_corrs): #not in is not working\n",
    "                        high_corrs.append((col1,col2,corr))\n",
    "        return list(set(high_corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train = pd.concat([y_train,X_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc_BothSexes+happy+doc_ratio+below_pov_line+gdp+gdppp+unemp+med_age+med_age_male+med_age_female+birth_sex_ratio+total_sex_ratio+literacy+hum_freedom+econ_freedom+gen_inequality+sunny_hours+rainfall+pop_dens+avg_temp+int_users+eth_div+ling_div+relig_div+wto+alc_cons+beer+wine+spirits+oth_alc+total_bmi+fem_bmi+male_bmi+r_home_war+elevation+guns+farmers+depression+children+urbanization+immigrants+population+homeless_dummy+marr_div_dummy+malnutrition_dummy+pov_ind_dummy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'+'.join(list(whole_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train=whole_train.drop(['gen_inequality','children','gdppp','med_age','med_age_male','male_bmi',\n",
    "                             'birth_sex_ratio','hum_freedom','econ_freedom','rainfall','fem_bmi','homeless_dummy',\n",
    "                             'marr_div_dummy','malnutrition_dummy','pov_ind_dummy','population','wto'],axis=1,\n",
    "                             errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>bc_BothSexes</td>   <th>  R-squared:         </th> <td>   0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 17 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.36e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:14:17</td>     <th>  Log-Likelihood:    </th> <td> -207.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   146</td>      <th>  AIC:               </th> <td>   473.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   117</td>      <th>  BIC:               </th> <td>   560.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    9.1320</td> <td>    3.443</td> <td>    2.653</td> <td> 0.009</td> <td>    2.314</td> <td>   15.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>happy</th>           <td>    0.1213</td> <td>    0.145</td> <td>    0.836</td> <td> 0.405</td> <td>   -0.166</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>doc_ratio</th>       <td>   -0.2806</td> <td>    0.178</td> <td>   -1.580</td> <td> 0.117</td> <td>   -0.632</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>below_pov_line</th>  <td>   -0.1374</td> <td>    0.166</td> <td>   -0.830</td> <td> 0.408</td> <td>   -0.465</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gdp</th>             <td>    0.0050</td> <td>    0.075</td> <td>    0.066</td> <td> 0.947</td> <td>   -0.143</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemp</th>           <td>   -0.0059</td> <td>    0.019</td> <td>   -0.305</td> <td> 0.761</td> <td>   -0.044</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>med_age_female</th>  <td>    0.0252</td> <td>    0.029</td> <td>    0.868</td> <td> 0.387</td> <td>   -0.032</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_sex_ratio</th> <td>    1.4682</td> <td>    1.740</td> <td>    0.844</td> <td> 0.401</td> <td>   -1.979</td> <td>    4.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>literacy</th>        <td>   -0.0256</td> <td>    0.021</td> <td>   -1.220</td> <td> 0.225</td> <td>   -0.067</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sunny_hours</th>     <td>   -0.0005</td> <td>    0.000</td> <td>   -1.702</td> <td> 0.091</td> <td>   -0.001</td> <td> 8.19e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_dens</th>        <td>   -0.1219</td> <td>    0.091</td> <td>   -1.346</td> <td> 0.181</td> <td>   -0.301</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_temp</th>        <td>   -0.0601</td> <td>    0.020</td> <td>   -2.966</td> <td> 0.004</td> <td>   -0.100</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_users</th>       <td>   -0.0281</td> <td>    0.010</td> <td>   -2.927</td> <td> 0.004</td> <td>   -0.047</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_div</th>         <td>    0.5394</td> <td>    0.585</td> <td>    0.922</td> <td> 0.358</td> <td>   -0.619</td> <td>    1.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ling_div</th>        <td>   -0.3300</td> <td>    0.550</td> <td>   -0.600</td> <td> 0.550</td> <td>   -1.420</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relig_div</th>       <td>   -0.1054</td> <td>    0.508</td> <td>   -0.207</td> <td> 0.836</td> <td>   -1.112</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alc_cons</th>        <td>    0.0959</td> <td>    0.036</td> <td>    2.665</td> <td> 0.009</td> <td>    0.025</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beer</th>            <td>    0.0096</td> <td>    0.007</td> <td>    1.470</td> <td> 0.144</td> <td>   -0.003</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wine</th>            <td>   -0.1559</td> <td>    0.120</td> <td>   -1.296</td> <td> 0.198</td> <td>   -0.394</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spirits</th>         <td>    0.0065</td> <td>    0.007</td> <td>    0.909</td> <td> 0.365</td> <td>   -0.008</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oth_alc</th>         <td>    0.2774</td> <td>    0.127</td> <td>    2.180</td> <td> 0.031</td> <td>    0.025</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_bmi</th>       <td>   -0.0701</td> <td>    0.078</td> <td>   -0.897</td> <td> 0.372</td> <td>   -0.225</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r_home_war</th>      <td>   -0.3293</td> <td>    0.298</td> <td>   -1.103</td> <td> 0.272</td> <td>   -0.920</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elevation</th>       <td>   -0.1726</td> <td>    0.117</td> <td>   -1.471</td> <td> 0.144</td> <td>   -0.405</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>guns</th>            <td>    0.0379</td> <td>    0.139</td> <td>    0.273</td> <td> 0.785</td> <td>   -0.237</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>farmers</th>         <td>   -0.0103</td> <td>    0.008</td> <td>   -1.244</td> <td> 0.216</td> <td>   -0.027</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depression</th>      <td>   -0.0008</td> <td>    0.001</td> <td>   -1.205</td> <td> 0.231</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urbanization</th>    <td>    0.0124</td> <td>    0.008</td> <td>    1.605</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>immigrants</th>      <td>    0.0346</td> <td>    0.096</td> <td>    0.361</td> <td> 0.719</td> <td>   -0.155</td> <td>    0.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.005</td> <th>  Durbin-Watson:     </th> <td>   1.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.223</td> <th>  Jarque-Bera (JB):  </th> <td>   2.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.271</td> <th>  Prob(JB):          </th> <td>   0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.342</td> <th>  Cond. No.          </th> <td>1.04e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.04e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           bc_BothSexes   R-squared:                       0.552\n",
       "Model:                            OLS   Adj. R-squared:                  0.445\n",
       "Method:                 Least Squares   F-statistic:                     5.150\n",
       "Date:                Wed, 17 Apr 2019   Prob (F-statistic):           1.36e-10\n",
       "Time:                        16:14:17   Log-Likelihood:                -207.76\n",
       "No. Observations:                 146   AIC:                             473.5\n",
       "Df Residuals:                     117   BIC:                             560.0\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           9.1320      3.443      2.653      0.009       2.314      15.950\n",
       "happy               0.1213      0.145      0.836      0.405      -0.166       0.408\n",
       "doc_ratio          -0.2806      0.178     -1.580      0.117      -0.632       0.071\n",
       "below_pov_line     -0.1374      0.166     -0.830      0.408      -0.465       0.191\n",
       "gdp                 0.0050      0.075      0.066      0.947      -0.143       0.153\n",
       "unemp              -0.0059      0.019     -0.305      0.761      -0.044       0.032\n",
       "med_age_female      0.0252      0.029      0.868      0.387      -0.032       0.083\n",
       "total_sex_ratio     1.4682      1.740      0.844      0.401      -1.979       4.915\n",
       "literacy           -0.0256      0.021     -1.220      0.225      -0.067       0.016\n",
       "sunny_hours        -0.0005      0.000     -1.702      0.091      -0.001    8.19e-05\n",
       "pop_dens           -0.1219      0.091     -1.346      0.181      -0.301       0.057\n",
       "avg_temp           -0.0601      0.020     -2.966      0.004      -0.100      -0.020\n",
       "int_users          -0.0281      0.010     -2.927      0.004      -0.047      -0.009\n",
       "eth_div             0.5394      0.585      0.922      0.358      -0.619       1.698\n",
       "ling_div           -0.3300      0.550     -0.600      0.550      -1.420       0.760\n",
       "relig_div          -0.1054      0.508     -0.207      0.836      -1.112       0.902\n",
       "alc_cons            0.0959      0.036      2.665      0.009       0.025       0.167\n",
       "beer                0.0096      0.007      1.470      0.144      -0.003       0.023\n",
       "wine               -0.1559      0.120     -1.296      0.198      -0.394       0.082\n",
       "spirits             0.0065      0.007      0.909      0.365      -0.008       0.021\n",
       "oth_alc             0.2774      0.127      2.180      0.031       0.025       0.529\n",
       "total_bmi          -0.0701      0.078     -0.897      0.372      -0.225       0.085\n",
       "r_home_war         -0.3293      0.298     -1.103      0.272      -0.920       0.262\n",
       "elevation          -0.1726      0.117     -1.471      0.144      -0.405       0.060\n",
       "guns                0.0379      0.139      0.273      0.785      -0.237       0.313\n",
       "farmers            -0.0103      0.008     -1.244      0.216      -0.027       0.006\n",
       "depression         -0.0008      0.001     -1.205      0.231      -0.002       0.001\n",
       "urbanization        0.0124      0.008      1.605      0.111      -0.003       0.028\n",
       "immigrants          0.0346      0.096      0.361      0.719      -0.155       0.224\n",
       "==============================================================================\n",
       "Omnibus:                        3.005   Durbin-Watson:                   1.848\n",
       "Prob(Omnibus):                  0.223   Jarque-Bera (JB):                2.494\n",
       "Skew:                           0.271   Prob(JB):                        0.287\n",
       "Kurtosis:                       3.342   Cond. No.                     1.04e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.04e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lregmodel = smf.ols(\"\"\"bc_BothSexes ~ happy+doc_ratio+below_pov_line+gdp+unemp+med_age_female+total_sex_ratio+literacy+sunny_hours+pop_dens+avg_temp+int_users+eth_div+ling_div+relig_div+alc_cons+beer+wine+spirits+oth_alc+total_bmi+r_home_war+elevation+guns+farmers+depression+urbanization+immigrants\"\"\"\n",
    "                     ,data=whole_train)\n",
    "results = lregmodel.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to start feature combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['gen_inequality','children','gdppp','med_age','med_age_male','male_bmi',\n",
    "                        'birth_sex_ratio','hum_freedom','econ_freedom','rainfall','fem_bmi','homeless_dummy',\n",
    "                        'marr_div_dummy','malnutrition_dummy','pov_ind_dummy','population','wto'],axis=1,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train_t=deepcopy(whole_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train_t['t_doc_lit'] = whole_train_t.doc_ratio * whole_train_t.literacy\n",
    "whole_train_t = whole_train_t.drop(['doc_ratio','literacy'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train_t['t_temp_sunny'] = whole_train_t.avg_temp * whole_train_t.sunny_hours\n",
    "whole_train_t = whole_train_t.drop(['avg_temp','sunny_hours'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train_t = whole_train_t.drop(['beer','wine','spirits','oth_alc','ling_div','med_age_female','r_home_war',\n",
    "                                    'unemp','below_pov_line','gdp','eth_div','relig_div','immigrants','urbanization',\n",
    "                                    'guns','happy','total_sex_ratio'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc_BothSexes+pop_dens+int_users+alc_cons+total_bmi+elevation+farmers+depression+t_doc_lit+t_temp_sunny'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'+'.join(list(whole_train_t.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>bc_BothSexes</td>   <th>  R-squared:         </th> <td>   0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 17 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>6.83e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:14:19</td>     <th>  Log-Likelihood:    </th> <td> -220.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   146</td>      <th>  AIC:               </th> <td>   461.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   136</td>      <th>  BIC:               </th> <td>   491.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   13.2308</td> <td>    1.855</td> <td>    7.132</td> <td> 0.000</td> <td>    9.562</td> <td>   16.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_dens</th>     <td>   -0.2204</td> <td>    0.074</td> <td>   -2.979</td> <td> 0.003</td> <td>   -0.367</td> <td>   -0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_users</th>    <td>   -0.0131</td> <td>    0.007</td> <td>   -1.905</td> <td> 0.059</td> <td>   -0.027</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alc_cons</th>     <td>    0.1372</td> <td>    0.031</td> <td>    4.470</td> <td> 0.000</td> <td>    0.077</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_bmi</th>    <td>   -0.1331</td> <td>    0.060</td> <td>   -2.228</td> <td> 0.028</td> <td>   -0.251</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elevation</th>    <td>   -0.2443</td> <td>    0.106</td> <td>   -2.296</td> <td> 0.023</td> <td>   -0.455</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>farmers</th>      <td>   -0.0130</td> <td>    0.008</td> <td>   -1.712</td> <td> 0.089</td> <td>   -0.028</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depression</th>   <td>   -0.0016</td> <td>    0.001</td> <td>   -2.705</td> <td> 0.008</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t_doc_lit</th>    <td>   -0.0076</td> <td>    0.003</td> <td>   -2.393</td> <td> 0.018</td> <td>   -0.014</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t_temp_sunny</th> <td> -2.57e-05</td> <td> 6.25e-06</td> <td>   -4.110</td> <td> 0.000</td> <td>-3.81e-05</td> <td>-1.33e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.142</td> <th>  Durbin-Watson:     </th> <td>   1.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.565</td> <th>  Jarque-Bera (JB):  </th> <td>   0.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.195</td> <th>  Prob(JB):          </th> <td>   0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.043</td> <th>  Cond. No.          </th> <td>1.06e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.06e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           bc_BothSexes   R-squared:                       0.464\n",
       "Model:                            OLS   Adj. R-squared:                  0.429\n",
       "Method:                 Least Squares   F-statistic:                     13.09\n",
       "Date:                Wed, 17 Apr 2019   Prob (F-statistic):           6.83e-15\n",
       "Time:                        16:14:19   Log-Likelihood:                -220.85\n",
       "No. Observations:                 146   AIC:                             461.7\n",
       "Df Residuals:                     136   BIC:                             491.5\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       13.2308      1.855      7.132      0.000       9.562      16.899\n",
       "pop_dens        -0.2204      0.074     -2.979      0.003      -0.367      -0.074\n",
       "int_users       -0.0131      0.007     -1.905      0.059      -0.027       0.000\n",
       "alc_cons         0.1372      0.031      4.470      0.000       0.077       0.198\n",
       "total_bmi       -0.1331      0.060     -2.228      0.028      -0.251      -0.015\n",
       "elevation       -0.2443      0.106     -2.296      0.023      -0.455      -0.034\n",
       "farmers         -0.0130      0.008     -1.712      0.089      -0.028       0.002\n",
       "depression      -0.0016      0.001     -2.705      0.008      -0.003      -0.000\n",
       "t_doc_lit       -0.0076      0.003     -2.393      0.018      -0.014      -0.001\n",
       "t_temp_sunny  -2.57e-05   6.25e-06     -4.110      0.000   -3.81e-05   -1.33e-05\n",
       "==============================================================================\n",
       "Omnibus:                        1.142   Durbin-Watson:                   1.829\n",
       "Prob(Omnibus):                  0.565   Jarque-Bera (JB):                0.935\n",
       "Skew:                           0.195   Prob(JB):                        0.627\n",
       "Kurtosis:                       3.043   Cond. No.                     1.06e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.06e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lregmodel = smf.ols(\"\"\"bc_BothSexes ~ pop_dens+int_users+alc_cons+total_bmi+elevation+farmers+depression+t_doc_lit+t_temp_sunny\"\"\"\n",
    "                     ,data=whole_train_t)\n",
    "results = lregmodel.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.348846019004694"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "np.mean(cross_val_score(lr,whole_train_t.iloc[:,1:],whole_train_t.iloc[:,0],scoring='r2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having gotten the best possible result through many iterations\n",
    "Time to try it on the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_eng_t = deepcopy(X_test)\n",
    "\n",
    "X_test_eng_t['gdp'] = np.log(X_test_eng_t.gdp)\n",
    "X_test_eng_t['total_sex_ratio'] = 1/(X_test_eng_t.total_sex_ratio)\n",
    "X_test_eng_t['guns'] = np.log(X_test_eng_t.guns+1)\n",
    "X_test_eng_t['doc_ratio'] = np.log(X_test_eng_t.doc_ratio)\n",
    "X_test_eng_t['pop_dens'] = np.log(X_test_eng_t.pop_dens)\n",
    "X_test_eng_t['elevation'] = np.log(X_test_eng_t.elevation)\n",
    "X_test_eng_t['immigrants'] = np.log(X_test_eng_t.immigrants)\n",
    "X_test_eng_t['literacy'] = (X_test_eng_t.literacy)**1/2\n",
    "X_test_eng_t['gdppp'] = np.log(X_test_eng_t.gdppp)\n",
    "X_test_eng_t['population'] = np.log(X_test_eng_t.population)\n",
    "X_test_eng_t['children'] = X_test_eng_t.children**2\n",
    "X_test_eng_t['below_pov_line'] = np.log(X_test_eng_t.below_pov_line)\n",
    "X_test_eng_t['wine'] = np.log(X_test_eng_t.wine+1)\n",
    "X_test_eng_t['oth_alc'] = np.log(X_test_eng_t.oth_alc+1)\n",
    "\n",
    "X_test_eng_t['t_doc_lit'] = X_test_eng_t.doc_ratio * X_test_eng_t.literacy\n",
    "X_test_eng_t = X_test_eng_t.drop(['doc_ratio','literacy'],axis=1)\n",
    "X_test_eng_t['t_temp_sunny'] = X_test_eng_t.avg_temp * X_test_eng_t.sunny_hours\n",
    "X_test_eng_t = X_test_eng_t.drop(['avg_temp','sunny_hours'],axis=1)\n",
    "\n",
    "X_test_eng_t = X_test_eng_t.loc[:,['pop_dens','int_users','alc_cons','total_bmi','elevation','farmers','depression',\n",
    "                                  't_doc_lit','t_temp_sunny']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = whole_train_t.iloc[:,1:]\n",
    "final_y_train = whole_train_t.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ols = LinearRegression()\n",
    "results = lm_ols.fit(final_X_train,final_y_train)\n",
    "\n",
    "predict = lm_ols.predict(X_test_eng_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox\n",
    "\n",
    "y_test = inv_boxcox(y_test,[.41719220590443856])\n",
    "predict = inv_boxcox(predict,[.41719220590443856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a26dd6940>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y_test,predict)\n",
    "plt.plot([0,18],[0,18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a 'est pas amlior. Dommage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
